{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import _pickle as pkl\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aa_knn(trainFeature,trainLabel,testFeature,k):\n",
    "    rows = testFeature.shape[0]\n",
    "    cols = testFeature.shape[1]\n",
    "\n",
    "    train_num = trainFeature.shape[0]\n",
    "    dist = np.zeros(shape=(train_num))\n",
    "    prediction = np.zeros(shape=(rows,trainLabel.shape[1]))\n",
    "\n",
    "    for i in range(rows):\n",
    "        test = testFeature[i,:]\n",
    "        for j in range(train_num):\n",
    "            train = trainFeature[j,:]\n",
    "            V = test - train\n",
    "            sqV = V**2\n",
    "            sqDis = sqV.sum(axis=0)\n",
    "            dist[j] = math.sqrt(sqDis)\n",
    "\n",
    "        indice = dist.argsort()\n",
    "        sort_dis = sorted(dist)\n",
    "        sum_label = np.zeros(shape=trainLabel.shape[1])\n",
    "        for l in range(k):\n",
    "            sum_label = sum_label + trainLabel[l,:]\n",
    "\n",
    "        prediction[i,:] = sum_label/k\n",
    "    \n",
    "    idx = prediction.argmax(axis=1)\n",
    "    prediction = (idx[:,None] == np.arange(prediction.shape[1])).astype(int)\n",
    "\n",
    "    return prediction   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_iteration(tolerance, trainFeature, trainLabel, sources=None):\n",
    "    if sources is None:\n",
    "        sources = {i: np.array([i]) for i in range(len(trainFeature))}\n",
    "    elif not isinstance(sources, dict):\n",
    "        sources = {i: np.where(sources == i)[0] for i in set(sources)}\n",
    "\n",
    "    idxs = np.random.permutation(len(sources))\n",
    "    marginal_contribs = np.zeros(len(trainFeature))\n",
    "\n",
    "    x_batch = np.zeros((0,trainFeature.shape[1]))\n",
    "    y_batch = np.zeros(0,float)\n",
    "\n",
    "    truncation_counter = 0\n",
    "\n",
    "    #源代码里面是随机抽取测试数据，进行100次实验获得到的平均socre，这里直接设置为零\n",
    "    new_score = 0\n",
    "\n",
    "    for _, idx in enumerate(idx):\n",
    "        old_score = new_score\n",
    "\n",
    "        x_batch = np.concatenate(x_batch, trainLabel[sources[idx]])\n",
    "        y_batch = np.concatenate(y_batch, trainFeature[sources[idx]])\n",
    "\n",
    "        if len(set(y_batch)) >= 2:\n",
    "            new_score = aa_knn()\n",
    "\n",
    "        marginal_contribs[sources[idx]] = (new_score - old_score)/len(sources[idx])\n",
    "        mean_score = 0.78\n",
    "\n",
    "        distance_to_full_score = np.abs(new_score - mean_score)\n",
    "        if distance_to_full_score <= tolerance * mean_score:\n",
    "            truncation_counter += 1\n",
    "            if truncation_counter > 5:\n",
    "                break\n",
    "        else:\n",
    "            truncation_counter = 0\n",
    "    return marginal_contribs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmc_shap(trainFeature, iterations, tolerance=None, sources=None):\n",
    "    if sources is None:\n",
    "        sources = {i: np.array([i]) for i in range(len(trainFeature))}\n",
    "    elif not isinstance(sources, dict):\n",
    "        sources = {i np.where(sources == i)[0] for i in set(sources)}\n",
    "\n",
    "    marginals = []\n",
    "    mem_tmc = np.zeros((0,len(trainFeature)))\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        idxs = np.random.permutation(len(sources))\n",
    "        marginal_contribs = np.zeros(len(trainFeature))\n",
    "\n",
    "        x_batch = np.zeros((0,trainFeature.shape[1]))\n",
    "        y_batch = np.zeros(0,float)\n",
    "\n",
    "        truncation_counter = 0\n",
    "\n",
    "        #源代码里面是随机抽取测试数据，进行100次实验获得到的平均socre，这里直接设置为零\n",
    "        new_score = 0\n",
    "\n",
    "        for _, idx in enumerate(idx):\n",
    "            old_score = new_score\n",
    "\n",
    "            x_batch = np.concatenate(x_batch, trainLabel[sources[idx]])\n",
    "            y_batch = np.concatenate(y_batch, trainFeature[sources[idx]])\n",
    "\n",
    "            if len(set(y_batch)) >= 2:\n",
    "                new_score = aa_knn()\n",
    "\n",
    "            marginal_contribs[sources[idx]] = (new_score - old_score)/len(sources[idx])\n",
    "            mean_score = 0.78\n",
    "\n",
    "            distance_to_full_score = np.abs(new_score - mean_score)\n",
    "            if distance_to_full_score <= tolerance * mean_score:\n",
    "                truncation_counter += 1\n",
    "                if truncation_counter > 5:\n",
    "                    break\n",
    "            else:\n",
    "                truncation_counter = 0\n",
    "        \n",
    "        mem_tmc = np.concatenate([mem_tmc, np.reshape(marginal_contribs, (1,-1))])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbasecondaa552d2f6e5da4ad6b3305c7b8c5f25f7",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}